import pandas as pd

# Read in track metadata with genre labels
tracks = pd.read_csv("/content/drive/MyDrive/fma-rock-vs-hiphop.csv")

# Read in track metrics with the features
echonest_metrics = pd.read_json("/content/drive/MyDrive/echonest-metrics.json", precise_float=True)

# Merge the relevant columns of tracks and echonest_metrics
echo_tracks = pd.merge(echonest_metrics, tracks[["track_id", "genre_top"]], on="track_id")

# Inspect the resultant dataframe
echo_tracks.info()

 Pairwise relationships between continuous variables

# Create a correlation matrix
corr_metrics = echo_tracks.select_dtypes(include=['number']).corr()
corr_metrics.style.background_gradient()

 Normalizing the feature data

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# Assuming echo_tracks is your DataFrame
# Define your features and labels
features = echo_tracks.drop(["genre_top", "track_id"], axis=1)
labels = echo_tracks["genre_top"]

# 1. Calculate mean and standard deviation before normalization
mean_before = features.mean()
std_before = features.std()

# 2. Standardize the features
scaler = StandardScaler()
scaled_train_features = scaler.fit_transform(features)

# 3. Create a DataFrame from the scaled features
scaled_features_df = pd.DataFrame(scaled_train_features, columns=features.columns)

# 4. Calculate mean and standard deviation after normalization
mean_after = scaled_features_df.mean()
std_after = scaled_features_df.std()

# 5. Prepare data for visualization
summary_stats = pd.DataFrame({
    'Mean Before': mean_before,
    'Mean After': mean_after,
    'Std Dev Before': std_before,
    'Std Dev After': std_after
})

# Reset index for better plotting
summary_stats.reset_index(inplace=True)
summary_stats.rename(columns={'index': 'Feature'}, inplace=True)

# 6. Plotting the means before and after normalization
plt.figure(figsize=(15, 6))
sns.barplot(data=summary_stats.melt(id_vars='Feature', value_vars=['Mean Before', 'Mean After']),
             x='Feature', y='value', hue='variable')
plt.title('Mean of Features Before and After Normalization')
plt.xticks(rotation=45)
plt.legend(title='Normalization')
plt.show()

# 7. Plotting the standard deviations before and after normalization
plt.figure(figsize=(15, 6))
sns.barplot(data=summary_stats.melt(id_vars='Feature', value_vars=['Std Dev Before', 'Std Dev After']),
             x='Feature', y='value', hue='variable')
plt.title('Standard Deviation of Features Before and After Normalization')
plt.xticks(rotation=45)
plt.legend(title='Normalization')
plt.show()

 Principal Component Analysis on our scaled data

# This is just to make plots appear in the notebook
%matplotlib inline

# Import our plotting module, and PCA class
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Get our explained variance ratios from PCA using all features
pca = PCA()
pca.fit(scaled_train_features)
exp_variance = pca.explained_variance_ratio_

print(pca.explained_variance_ratio_)
print(pca.n_components_)

# plot the explained variance using a barplot
fig, ax = plt.subplots()
ax.bar(range(8), exp_variance)
ax.set_xlabel('Principal Component #')



# Import numpy
import numpy as np

# Calculate the cumulative explained variance
cum_exp_variance = np.cumsum(exp_variance)

# Plot the cumulative explained variance and draw a dashed line at 0.90.
fig, ax = plt.subplots()
ax.plot(range(8), cum_exp_variance)
ax.axhline(y=0.9, linestyle='--')


Further Visualization of PCA

n_components = 6

# Perform PCA with the chosen number of components and project data onto components
pca = PCA(n_components, random_state=10)
pca.fit(scaled_train_features)
pca_projection = pca.transform(scaled_train_features)

# Import train_test_split function and Decision tree classifier
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# Split our data
train_features, test_features, train_labels, test_labels = train_test_split(pca_projection, labels, random_state=10)

# Train our decision tree
tree = DecisionTreeClassifier(random_state=10)
tree.fit(train_features, train_labels)

# Predict the labels for the test data
pred_labels_tree = tree.predict(test_features)

# Import LogisticRegression
from sklearn.linear_model import LogisticRegression

# Train our logistic regression and predict labels for the test set
logreg = LogisticRegression(random_state=10)
logreg.fit(train_features, train_labels)
pred_labels_logit = logreg.predict(test_features)

# Create the classification report for both models
from sklearn.metrics import classification_report
class_rep_tree = classification_report(test_labels, pred_labels_tree)
class_rep_log = classification_report(test_labels, pred_labels_logit)

print("Decision Tree: \n", class_rep_tree)
print("Logistic Regression: \n", class_rep_log)

# Subset only the hip-hop tracks, and then only the rock tracks
hop_only = echo_tracks.loc[echo_tracks["genre_top"] == "Hip-Hop"]

# sample the rocks songs to be the same number as there are hip-hop songs
rock_only = echo_tracks.loc[echo_tracks["genre_top"] == "Rock"].sample(len(hop_only), random_state=10)

# concatenate the dataframes rock_only and hop_only
rock_hop_bal = pd.concat([rock_only, hop_only])

# The features, labels, and pca projection are created for the balanced dataframe
features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1)
labels = rock_hop_bal['genre_top']
pca_projection = pca.fit_transform(scaler.fit_transform(features))

# Redefine the train and test set with the pca_projection from the balanced data
train_features, test_features, train_labels, test_labels = train_test_split(pca_projection, labels, random_state=10)

# Train our decision tree on the balanced data
tree = DecisionTreeClassifier(random_state=10)
tree.fit(train_features, train_labels)
pred_labels_tree = tree.predict(test_features)

# Train our logistic regression on the balanced data
logreg = LogisticRegression(random_state=10)
logreg.fit(train_features, train_labels)
pred_labels_logit = logreg.predict(test_features)

# Compare the models
print("Decision Tree: \n", classification_report(test_labels, pred_labels_tree))
print("Logistic Regression: \n", classification_report(test_labels, pred_labels_logit))

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold, cross_val_score

# Define KFold cross-validator
kf = KFold(n_splits=5, shuffle=True, random_state=10)

# Train the SVM model on the balanced data
svm_model = SVC(random_state=10)
svm_model.fit(train_features, train_labels)

# Predict the labels for the test data
pred_labels_svm = svm_model.predict(test_features)

# Create the classification report for the SVM model
class_rep_svm = classification_report(test_labels, pred_labels_svm)
print("SVM: \n", class_rep_svm)
# Train our SVM model using KFold cv
svm_score = cross_val_score(svm_model, pca_projection, labels, cv=kf)

# Print the mean of the SVM scores
print("SVM:", np.mean(svm_score))

from sklearn.model_selection import KFold, cross_val_score

# Set up our K-fold cross-validation
# Setting shuffle=True to allow random_state to have an effect
kf = KFold(n_splits=10, shuffle=True, random_state=10)

tree = DecisionTreeClassifier(random_state=10)
logreg = LogisticRegression(random_state=10)

# Train our models using KFold cv
tree_score = cross_val_score(tree, pca_projection, labels, cv=kf)
logit_score = cross_val_score(logreg, pca_projection, labels, cv=kf)

# Print the mean of each array of scores
print("Decision Tree:", np.mean(tree_score), "Logistic Regression:", np.mean(logit_score))

pip install gradio

import gradio as gr
import numpy as np

# Define the Gradio interface
def gradio_interface(scaler, pca):
    def predict_genre(model_type, acousticness, danceability, energy, instrumentalness, liveness, speechiness, tempo, valence):
        features_array = np.array([[acousticness, danceability, energy, instrumentalness, liveness, speechiness, tempo, valence]])
        scaled_features = scaler.transform(features_array)
        pca_features = pca.transform(scaled_features)

        # Select the model based on the model_type
        if model_type == "SVM":
            model = svm_model
        elif model_type == "Logistic Regression":
            model = logreg


        # Predict the genre using the selected model
        predicted_genre = model.predict(pca_features)
        return predicted_genre[0]  # Return the genre as a string

    with gr.Blocks() as demo:
        gr.Markdown("### Music Genre Prediction")

        # Dropdown to select the model
        model_type = gr.Dropdown(choices=["SVM", "Logistic Regression"], label="Select Model")

        # Input fields for audio features
        acousticness = gr.Slider(minimum=0, maximum=1, label="Acousticness")
        danceability = gr.Slider(minimum=0, maximum=1, label="Danceability")
        energy = gr.Slider(minimum=0, maximum=1, label="Energy")
        instrumentalness = gr.Slider(minimum=0, maximum=1, label="Instrumentalness")
        liveness = gr.Slider(minimum=0, maximum=1, label="Liveness")
        speechiness = gr.Slider(minimum=0, maximum=1, label="Speechiness")
        tempo = gr.Slider(minimum=0, maximum=300, label="Tempo (BPM)")
        valence = gr.Slider(minimum=0, maximum=1, label="Valence")

        # Button to make prediction
        predict_button = gr.Button("Predict Genre")

        # Output label for the prediction
        output_label = gr.Label("Predicted Genre: ")

        # Define the prediction action
        def predict_action(model_type, acousticness, danceability, energy, instrumentalness, liveness, speechiness, tempo, valence):
            genre = predict_genre(model_type, acousticness, danceability, energy, instrumentalness, liveness, speechiness, tempo, valence)
            return genre

        # Set the button action
        predict_button.click(predict_action, inputs=[model_type, acousticness, danceability, energy, instrumentalness, liveness, speechiness, tempo, valence], outputs=output_label)

    return demo

# Launch the Gradio app
demo = gradio_interface(scaler, pca)  # Pass the scaler and PCA
demo.launch()  # Launch the Gradio app
